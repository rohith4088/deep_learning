{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful\n"
     ]
    }
   ],
   "source": [
    "#deep fake detection\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import Conv1D,Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras import backend as k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu accelaration on online editors\n",
    "# import tensorflow as tf\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODING THE GENERATIVE ADVERSARIAL  NETWORK\n",
    "#oading the functions\n",
    "#dense--> noise layer of the network\n",
    "#conv2dtranspose--> it enalbes us to convolve and upsacale the image at the same time\n",
    "#it is equivalent to upsampling2d followed by conv2d\n",
    "#LeakyRelu-->avoids gardeint vainsh problem\n",
    "#BatchNormalisation--> helps to normalise the covultion result\n",
    "#reshape--> helps to convert 1D array to 3D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES ON GANS\n",
    "#, Minimax is a competition among Discriminator “D” and Generator “G”. “D” tries increment the\n",
    "# possibility that accurately distinguishes true(real) and phoney (log D(x)), while “G” tries to decrease the possibility\n",
    "# that D will forecast that its outputs seem to be counterfeit “log(1-D(G(z))”. In the aforementioned research paper, the\n",
    "# GAN error rate estimated by calculation of loss can be noticed in equation 1 [4].\n",
    "# 𝐺minD𝑚ax 𝑉(𝐷, 𝐺) = 𝐸x ~𝑝𝑑ata(𝑥)[𝑙ogD(𝑥)] + 𝐸𝐸𝐸𝐸~𝑝𝑝𝑧𝑧(𝑧𝑧)[𝑙𝑙𝑙𝑙𝑙𝑙(1 − 𝐷𝐷(𝐺𝐺(𝑧𝑧)))] (1)\n",
    "# Where; G stands for Generator, D stands for Discriminator, Pdata(x) = real-world data distribution, P(z) = generator\n",
    "# distribution, x = Pdata sample (x),z = a sample taken from P (z), D(x) denotes a discriminator network, G(z) denotes\n",
    "# the generator network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import os \n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import imageio\n",
    "from IPython import display\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Obtaining dependency information for imageio from https://files.pythonhosted.org/packages/c7/b0/7b6c35b8636ed773325cdb6f5ac3cd36afba63d99e20ed59c521cf5018b4/imageio-2.31.1-py3-none-any.whl.metadata\n",
      "  Downloading imageio-2.31.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: numpy in /Users/rohithr/anaconda3/envs/myenv/lib/python3.9/site-packages (from imageio) (1.23.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/rohithr/anaconda3/envs/myenv/lib/python3.9/site-packages (from imageio) (9.4.0)\n",
      "Downloading imageio-2.31.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio\n",
      "Successfully installed imageio-2.31.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAOD AND PREPARE THE DATA\n",
    "(train_images,train_labels),(_,_) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0],28,28,1).astype('float32')\n",
    "#train_images.shape[0],28,28,1 means 0--> upsampling 28x28--> size, 1 means --> greyscale for color value is 3(rgb)\n",
    "train_images = (train_images-127.5)/127.5 #normalize between [-1,1]\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "#batch and shuffle the data\n",
    "train_dataset  = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BATCH_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE THE MODEL\n",
    "#THE GENERATOR\n",
    "def the_generator():\n",
    "    model = tf.keras.layers.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias = False,input_shape = (100,)))\n",
    "    model.add(layers.BatchNormalisation())\n",
    "    model.add(layers.LeakyRelu())\n",
    "    model.add(layers.Reshape(7,7,256))#7 rows , 7 coloumns and 256 channels\n",
    "    assert model.output_shape == (None,7,7,265) #checks if the input size is (batch_size,7,7,256)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
