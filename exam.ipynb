{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exmapleremovingstop_words'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def remove_stop(sentence):\n",
    "    words = sentence.split()\n",
    "    res = [word for word in words if word not in stop_words]\n",
    "    return ''.join(res)\n",
    "\n",
    "remove_stop(\"this is an exmaple for removing stop_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--word--            --stem--            \n",
      "programming         program             \n",
      "programs            program             \n",
      "programmer          programm            \n",
      "programs            program             \n"
     ]
    }
   ],
   "source": [
    "#implementing stemming\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "example = ['programming','programs','programmer','programs']\n",
    "print(\"{0:20}{1:20}\".format(\"--word--\",\"--stem--\"))\n",
    "for word in example:\n",
    "    print(\"{0:20}{1:20}\".format(word,ps.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rohithr/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rohithr/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--word--            --lemma--           \n",
      "program             program             \n",
      "programming         program             \n",
      "programer           programer           \n",
      "programs            program             \n",
      "programmed          program             \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "wnl = WordNetLemmatizer()\n",
    "example_words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
    "print(\"{0:20}{1:20}\".format(\"--word--\",\"--lemma--\"))\n",
    "for word in example_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wnl.lemmatize(word,pos = 'v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/rohithr/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--word--            --lemma--           \n",
      "program             program             \n",
      "programming         program             \n",
      "programer           programer           \n",
      "programs            program             \n",
      "programmed          program             \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "wnl = WordNetLemmatizer()\n",
    "words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
    "print(\"{0:20}{1:20}\".format(\"--word--\",\"--lemma--\"))\n",
    "for word in words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wnl.lemmatize(word,pos = 'v')))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/rohithr/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7575\n",
      "my name is rohith neg\n",
      "the movie was good pos\n",
      "the movie was bad neg\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk import FreqDist\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "import random\n",
    "nltk.download(\"movie_reviews\")\n",
    "def extract_features(word):\n",
    "    return dict(FreqDist(word))\n",
    "docs = [(list(movie_reviews.words(fileid)),category)for category in movie_reviews.categories() \n",
    "        for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(docs)\n",
    "split_ratio = int(len(docs)*0.8)\n",
    "train_set,test_set = docs[:split_ratio],docs[split_ratio:]\n",
    "train_features = [(extract_features(words),category) for (words,category)in train_set]\n",
    "test_features = [(extract_features(words),category) for (words,category) in test_set]\n",
    "classifier = NaiveBayesClassifier.train(train_features)\n",
    "accuracy = classify.accuracy(classifier,test_features)\n",
    "print(accuracy)\n",
    "new_sent = [\"my name is rohith\",\"the movie was good\",\"the movie was bad\"]\n",
    "\n",
    "for sent in new_sent:\n",
    "    words = nltk.word_tokenize(sent)\n",
    "    features = extract_features(words)\n",
    "    print(sent,classifier.classify(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
